{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation English-Hindi Example Using IronMan Seq2Seq\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)\n",
    "  1. [Permissions and environment variables](#Permissions-and-environment-variables)\n",
    "  2. [Data Ingestion](#Data-Ingestion)\n",
    "3. [Training the Machine Translation model](#Training-the-Machine-Translation-model)\n",
    "4. [Set up hosting for the model](#Set-up-hosting-for-the-model)\n",
    "  1. [Import model into hosting](#Import-model-into-hosting)\n",
    "  2. [Create endpoint configuration](#Create-endpoint-configuration)\n",
    "  3. [Create endpoint](#Create-endpoint)\n",
    "  4. [Validate the model for use](#Validate-the-model-for-use)\n",
    "5. [Use a pretrained model](#Use-a-pretrained-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Welcome to our Machine Translation end-to-end example! In this demo, we will train a English-Hindi translation model and will test the predictions on a few examples.\n",
    "\n",
    "IronMan seq2seq algorithm is built on top of [Sockeye](https://github.com/awslabs/sockeye), a sequence-to-sequence framework for Neural Machine Translation based on MXNet. IronMan Seq2Seq implements state-of-the-art encoder-decoder architectures which can also be used for tasks like Abstractive Summarization in addition to Machine Translation.\n",
    "\n",
    "To get started, we need to set up the environment with a few prerequisite steps, for permissions, configurations, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prequisites and Preprocessing\n",
    "\n",
    "### Permissions and environment variables\n",
    "\n",
    "Here we set up the linkage and authentication to AWS services. There are three parts to this:\n",
    "\n",
    "1. The credentials and region for the account that's running training. Upload the credentials in the normal AWS credentials file format using the jupyter upload feature. The region must always be `us-west-2` during the Beta program.\n",
    "2. The roles used to give learning and hosting access to your data. See the documentation for how to specify these.\n",
    "3. The S3 bucket that you want to use for training and model data.\n",
    "\n",
    "_Note:_ Credentials for hosted notebooks will be automated before the final release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# For plotting attention matrix later on\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AWS_DEFAULT_REGION']='us-west-2'\n",
    "os.environ['AWS_SHARED_CREDENTIALS_FILE'] = os.getcwd() + '/credentials'\n",
    "\n",
    "s3_access_role = 'arn:aws:iam::317790470510:role/IronManAccessRole'\n",
    "model_role = 'arn:aws:iam::317790470510:role/IronManAccessRole'  \n",
    "\n",
    "# ECS Docker image for IM Seq2Seq.\n",
    "docker_image = \"032969728358.dkr.ecr.us-west-2.amazonaws.com/seq2seq:latest\"\n",
    "\n",
    "# S3 bucket that stores training and validation data.\n",
    "bucket = 'https://s3-us-west-2.amazonaws.com/seq2seq-data/eng-hindi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion\n",
    "\n",
    "We download the [IIT Bombay English-Hindi Parallel Corpus](http://www.cfilt.iitb.ac.in/iitb_parallel/) and store the training and validation dataset in our S3 bucket under **train** and **val** subfolders respectively. The current interface **_(subject to change)_** expects a parallel corpus with 2 files in each of the train and val subfolders (with **source** and **target** keywords in the filename). IronMan Seq2Seq expects already tokenized data (whitespace separated) as the input. The IIT Bombay corpus has already been tokenized for us. However, keep this in mind for any other data set you want to use with Seq2Seq. So, we upload 4 files in the S3 bucket:\n",
    "\n",
    "For training:\n",
    "- https://s3-us-west-2.amazonaws.com/seq2seq-data/eng-hindi/train/IITB.en-hi.en.source\n",
    "- https://s3-us-west-2.amazonaws.com/seq2seq-data/eng-hindi/train/IITB.en-hi.hi.target\n",
    "\n",
    "For validation:\n",
    "- https://s3-us-west-2.amazonaws.com/seq2seq-data/eng-hindi/val/dev.en.source\n",
    "- https://s3-us-west-2.amazonaws.com/seq2seq-data/eng-hindi/val/dev.hi.target\n",
    "\n",
    "Please note the use of keywords **source** and **target** in the filenames. It is a requirement for IronMan Seq2Seq to recognize the source and target files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Machine Translation model\n",
    "\n",
    "Once we have the data available in the correct format for training, the next step is to actually train the model using the data.\n",
    "\n",
    "After setting training parameters, we kick off training, and poll for status until training is completed, which in this example, takes between **6-8 hours on p2.8xlarge**. If you want to test it in less than 25-30 min, you can disable the comment on the **`\"max_updates\":\"1100\"`** hyperparameter below. However, this will not produce a good model. So, you can use the link below to host a pretrained model.\n",
    "\n",
    "Please refer to the documentation for full understanding and usage of the hyperparameters.\n",
    "\n",
    "### Skip to [Use a pretrained model](#Use-a-pretrained-model) to play with a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job translation-eng-hindi-2017-11-03-03-39-57\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-866d5fd6fd56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\njob_name = \\'translation-eng-hindi-\\' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\\nprint(\"Training job\", job_name)\\n\\ncreate_training_params = \\\\\\n{\\n    \"AlgorithmSpecification\": {\\n        \"TrainingImage\": docker_image,\\n        \"TrainingInputMode\": \"File\"\\n    },\\n    \"RoleArn\": s3_access_role,\\n    \"OutputDataConfig\": {\\n        \"S3OutputPath\": bucket\\n    },\\n    \"ResourceConfig\": {\\n        \"InstanceCount\": 1,\\n        \"InstanceType\": \"p2.8xlarge\",\\n        \"VolumeSizeInGB\": 50\\n    },\\n    \"TrainingJobName\": job_name,\\n    \"HyperParameters\": {\\n        \"rnn_num_hidden\":\"512\",\\n        \"batch_size\":\"128\",\\n        \"monitor_bleu\": \"1000\",\\n        \"device_ids\":\"-8\",\\n#         \"max_updates\":\"1100\",\\n        \"attention_type\":\"dot\",\\n        \"max_num_checkpoint_not_improved\":\"2\",\\n        \"keep_last_params\":\"3\"\\n    },\\n    \"StoppingCondition\": {\\n        \"MaxRuntimeInHours\": 15\\n    },\\n    \"InputDataConfig\": [\\n        {\\n            \"ChannelName\": \"train\",\\n            \"DataSource\": {\\n                \"S3DataSource\": {\\n                    \"S3DataType\": \"S3Prefix\",\\n                    \"S3Uri\": bucket + \\'/train\\',\\n                    \"S3DataDistributionType\": \"FullyReplicated\"\\n                }\\n            },\\n        },\\n        {\\n            \"ChannelName\": \"validation\",\\n            \"DataSource\": {\\n                \"S3DataSource\": {\\n                    \"S3DataType\": \"S3Prefix\",\\n                    \"S3Uri\": bucket + \\'/val\\',\\n                    \"S3DataDistributionType\": \"FullyReplicated\"\\n                }\\n            },\\n        }\\n    ]\\n}\\n\\nease = boto3.client(\\'im\\')\\nease.create_training_job(**create_training_params)\\n\\nstatus = ease.describe_training_job(TrainingJobName=job_name)[\\'TrainingJobStatus\\']\\nprint(status)\\nwhile status !=\\'Completed\\' and status!=\\'Failed\\':\\n    time.sleep(20)\\n    status = ease.describe_training_job(TrainingJobName=job_name)[\\'TrainingJobStatus\\']\\n    print(status)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ec2-user/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/conda/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/conda/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "job_name = 'translation-eng-hindi-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Training job\", job_name)\n",
    "\n",
    "create_training_params = \\\n",
    "{\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": docker_image,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"RoleArn\": s3_access_role,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": bucket\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"p2.8xlarge\",\n",
    "        \"VolumeSizeInGB\": 50\n",
    "    },\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"HyperParameters\": {\n",
    "        \"rnn_num_hidden\":\"512\",\n",
    "        \"batch_size\":\"128\",\n",
    "        \"monitor_bleu\": \"1000\",\n",
    "        \"device_ids\":\"-8\",\n",
    "#         \"max_updates\":\"1100\",\n",
    "        \"attention_type\":\"dot\",\n",
    "        \"max_num_checkpoint_not_improved\":\"2\",\n",
    "        \"keep_last_params\":\"3\"\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInHours\": 15\n",
    "    },\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": bucket + '/train',\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": bucket + '/val',\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "ease = boto3.client('im')\n",
    "ease.create_training_job(**create_training_params)\n",
    "\n",
    "status = ease.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "print(status)\n",
    "while status !='Completed' and status!='Failed':\n",
    "    time.sleep(20)\n",
    "    status = ease.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "    print(status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now wait for the model artifacts to get uploaded to S3\n",
      "and proceed to the next step after you see translation-eng-hindi-2017-11-03-00-00-28 folder\n",
      "in your S3 bucket.\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Now wait for the model artifacts to get uploaded to S3\n",
    "and proceed to the next step after you see %s folder\n",
    "in your S3 bucket.\"\"\" % job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up hosting for the model\n",
    "\n",
    "### Skip to [Use a pretrained model](#Use-a-pretrained-model) to play with a pretrained model\n",
    "\n",
    "In order to set up hosting, we have to import the model from training to hosting. A common question would be, why wouldn't we automatically go from training to hosting? As we worked through examples of what customers were looking to do with hosting, we realized that the Amazon ML model of hosting was unlikely to be sufficient for all customers.\n",
    "\n",
    "As a result, we have introduced some flexibility with respect to model deployment, with the goal of additional model deployment targets after launch. In the short term, that introduces some complexity, but we are actively working on making that easier for customers, even before GA.\n",
    "\n",
    "### Import model into hosting\n",
    "Next, you register the model with hosting. This allows you the flexibility of importing models trained elsewhere, as well as the choice of not importing models if the target of model creation is AWS Lambda, AWS Greengrass, Amazon Redshift, Amazon Athena, or other deployment target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "im = boto3.client('im')\n",
    "\n",
    "model_name=job_name + '-model'\n",
    "print(model_name)\n",
    "\n",
    "info = im.describe_training_job(TrainingJobName=job_name)\n",
    "model_data = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(model_data)\n",
    "\n",
    "primary_container = {\n",
    "    'Image': \"032969728358.dkr.ecr.us-west-2.amazonaws.com/seq2seq:latest\",\n",
    "    'ModelDataUrl': model_data\n",
    "}\n",
    "\n",
    "create_model_response = im.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = model_role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint configuration\n",
    "At launch, we will support configuring REST endpoints in hosting with multiple models, e.g. for A/B testing purposes. In order to support this, customers create an endpoint configuration, that describes the distribution of traffic across the models, whether split, shadowed, or sampled in some way.\n",
    "\n",
    "In addition, the endpoint configuration describes the instance type required for model deployment, and at launch will describe the autoscaling configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2SeqEndpointConfig-2017-11-03-00-27-38\n",
      "Endpoint Config Arn: arn:aws:im:us-west-2:032969728358:endpoint-config/Seq2SeqEndpointConfig-2017-11-03-00-27-38\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "endpoint_config_name = 'Seq2SeqEndpointConfig-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = im.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'p2.xlarge',\n",
    "        'MaxInstanceCount':1,\n",
    "        'MinInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint\n",
    "Lastly, the customer creates the endpoint that serves up the model, through specifying the name and configuration defined above. The end result is an endpoint that can be validated and incorporated into production applications. This takes 9-11 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2SeqEndpoint-2017-11-03-01-17-43\n",
      "arn:aws:im:us-west-2:032969728358:endpoint/Seq2SeqEndpoint-2017-11-03-01-17-43\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:im:us-west-2:032969728358:endpoint/Seq2SeqEndpoint-2017-11-03-01-17-43\n",
      "Status: InService\n",
      "CPU times: user 64 ms, sys: 12 ms, total: 76 ms\n",
      "Wall time: 9min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "endpoint_name = 'Seq2SeqEndpoint-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "create_endpoint_response = im.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print(create_endpoint_response['EndpointArn'])\n",
    "\n",
    "resp = im.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Creating':\n",
    "    time.sleep(60)\n",
    "    resp = im.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp['EndpointStatus']\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp['EndpointArn'])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the model for use\n",
    "Finally, the customer can now validate the model for use. They can obtain the endpoint from the client library using the result from previous operations, and generate predictions from the trained model using that endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "invocation_endpoint = \"https://maeveruntime.prod.us-west-2.ml-platform.aws.a2z.com\"\n",
    "runtime = boto3.Session().client(service_name='runtime.maeve', endpoint_url=invocation_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'target': 'आप कैसे हैं ?'}]\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 363 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "payload = ['how are you ? ' ]\n",
    "\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType='application/json', \n",
    "                                   Body=json.dumps(payload))\n",
    "\n",
    "response = response[\"Body\"].read().decode(\"utf-8\")\n",
    "response = json.loads(response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating model, endpoint and endpoint config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EngHindi-2017-11-03-04-13-12\n",
      "arn:aws:im:us-west-2:317790470510:model/EngHindi-2017-11-03-04-13-12\n",
      "EngHindiEndpointConfigOrchid-2017-11-03-04-13-12\n",
      "Endpoint Config Arn: arn:aws:im:us-west-2:317790470510:endpoint-config/EngHindiEndpointConfigOrchid-2017-11-03-04-13-12\n",
      "EngHindiEndpointOrchid-2017-11-03-04-13-12\n",
      "arn:aws:im:us-west-2:317790470510:endpoint/EngHindiEndpointOrchid-2017-11-03-04-13-12\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:im:us-west-2:317790470510:endpoint/EngHindiEndpointOrchid-2017-11-03-04-13-12\n",
      "Status: InService\n",
      "CPU times: user 60 ms, sys: 4 ms, total: 64 ms\n",
      "Wall time: 9min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pretrained_model_s3 = \"https://s3-us-west-2.amazonaws.com/seq2seq-data/eng-hindi/seq2seq-testing-eng-hindi-2017-11-01-22-26-44/model.tar.gz\"\n",
    "\n",
    "im = boto3.client('im')\n",
    "model_name = 'EngHindi-'  + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(model_name)\n",
    "\n",
    "primary_container = {\n",
    "    'Image': \"032969728358.dkr.ecr.us-west-2.amazonaws.com/seq2seq:latest\",\n",
    "    'ModelDataUrl': pretrained_model_s3\n",
    "}\n",
    "\n",
    "create_model_response = im.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = model_role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])\n",
    "\n",
    "endpoint_config_name = 'EngHindiEndpointConfigOrchid-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = im.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'p2.xlarge',\n",
    "        'MaxInstanceCount':1,\n",
    "        'MinInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])\n",
    "\n",
    "endpoint_name = 'EngHindiEndpointOrchid-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "create_endpoint_response = im.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print(create_endpoint_response['EndpointArn'])\n",
    "\n",
    "resp = im.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Creating':\n",
    "    time.sleep(60)\n",
    "    resp = im.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp['EndpointStatus']\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp['EndpointArn'])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "invocation_endpoint = \"https://maeveruntime.prod.us-west-2.ml-platform.aws.a2z.com\"\n",
    "runtime = boto3.Session().client(service_name='runtime.maeve', endpoint_url=invocation_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "payload = ['this is working now.',\n",
    "           'I love flowers',\n",
    "           'I will go out',\n",
    "           'I am your friend' ]\n",
    "\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType='application/json', \n",
    "                                   Body=json.dumps(payload))\n",
    "\n",
    "response = response[\"Body\"].read().decode(\"utf-8\")\n",
    "response = json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 'यह काम कर रहा है ।'},\n",
       " {'target': 'मैं फूलों से प्यार करता हूँ'},\n",
       " {'target': 'मैं बाहर जा रहा हूँ'},\n",
       " {'target': 'मैं तुम्हारा दोस्त हूँ'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving the Attention Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing `ContentType='application/json;attention_matrix=True'` will return the attention matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: what is your age ? \n",
      "Target: आपकी उम्र क्या है ?\n"
     ]
    }
   ],
   "source": [
    "payload = ['what is your age ?']\n",
    "\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType='application/json;attention_matrix=True', \n",
    "                                   Body=json.dumps(payload))\n",
    "\n",
    "response = response[\"Body\"].read().decode(\"utf-8\")\n",
    "response = json.loads(response)\n",
    "\n",
    "source = payload[0]\n",
    "target = response[0][\"target\"]\n",
    "attention_matrix = np.array(response[0][\"matrix\"])\n",
    "\n",
    "print(\"Source: %s \\nTarget: %s\" % (source, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Install the Hindi font for attention matrix\n",
    "!sudo wget https://cghs.nic.in/mangal.ttf -o /usr/share/fonts/mangal.ttf\n",
    "hindi_font = FontProperties(fname = 'mangal.ttf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_matrix(attention_matrix, target, source):\n",
    "    source_tokens = source.split()\n",
    "    target_tokens = target.split()\n",
    "    assert attention_matrix.shape[0] == len(target_tokens)\n",
    "    plt.imshow(attention_matrix.transpose(), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "    plt.xlabel(\"target\")\n",
    "    plt.ylabel(\"source\")\n",
    "    plt.gca().set_xticks([i for i in range(0, len(target_tokens))])\n",
    "    plt.gca().set_yticks([i for i in range(0, len(source_tokens))])\n",
    "    plt.gca().set_xticklabels(target_tokens, fontproperties=hindi_font)\n",
    "    plt.gca().set_yticklabels(source_tokens)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASUAAAEYCAYAAAAag+AEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nktQUS0lSUywlSU2xlCQ1xVKS1JT/BjT4xqE9EBE3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9eea6922b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_matrix(attention_matrix, target, source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
